{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78e3ac8d-57ff-4309-86ed-1d2e2e1de543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/samael/anaconda3/envs/webCrawler/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/samael/anaconda3/envs/webCrawler/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting numpy>=1.20.3 (from pandas)\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/samael/anaconda3/envs/webCrawler/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab304e-3263-4212-a3f8-17e690b39188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# 初始化WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 打開目標網站並等待手動登錄\n",
    "driver.get('https://www.rootdata.com/zh/login?fromUrl=%2Fzh%2FInvestors')\n",
    "\n",
    "# 等待手動登錄完成\n",
    "time.sleep(30)\n",
    "\n",
    "def extract_data(status):\n",
    "    data = []\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        print(f\"Currently on page {page_number} of {status} projects\")\n",
    "        \n",
    "        # 找到包含項目信息的表格\n",
    "        table = driver.find_element(By.CSS_SELECTOR, 'table')\n",
    "        \n",
    "        # 獲取所有項目的行\n",
    "        rows = table.find_elements(By.CSS_SELECTOR, 'tbody tr')\n",
    "        \n",
    "        for row in rows:\n",
    "            try:\n",
    "                name = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"1\"] a.list_name').text.strip()\n",
    "            except:\n",
    "                name = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                project_url = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"1\"] a.list_name').get_attribute('href')\n",
    "            except:\n",
    "                project_url = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                founded = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"2\"]').text.strip()\n",
    "            except:\n",
    "                founded = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                latest_investment = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"3\"]').text.strip()\n",
    "            except:\n",
    "                latest_investment = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                round_1year = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"4\"]').text.strip()\n",
    "            except:\n",
    "                round_1year = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                portfolio = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"5\"]').text.strip()\n",
    "            except:\n",
    "                portfolio = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                total_raised = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"6\"]').text.strip()\n",
    "            except:\n",
    "                total_raised = \"- -\"\n",
    "            \n",
    "            data.append([status, name, project_url, founded, latest_investment, round_1year, portfolio, total_raised])\n",
    "        \n",
    "        # 檢查是否存在下一頁按鈕\n",
    "        try:\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # 等待頁面加載新數據\n",
    "            page_number += 1\n",
    "        except:\n",
    "            print(\"No more pages or an error occurred.\")\n",
    "            break\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 爬取活躍項目數據\n",
    "active_data = extract_data(\"Active\")\n",
    "print(\"Finish crawl active project\")\n",
    "\n",
    "# 刷新頁面並等待手動選擇“不活躍”過濾器\n",
    "driver.refresh()\n",
    "time.sleep(30)\n",
    "\n",
    "# 爬取不活躍項目數據\n",
    "inactive_data = extract_data(\"Inactive\")\n",
    "\n",
    "# 將數據寫入CSV文件\n",
    "with open('investors.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Status', 'Name', 'URL', 'Founded', 'Latest Investment', 'Round (1 Year)', 'Portfolio', 'Total Raised'])\n",
    "    writer.writerows(active_data)\n",
    "    writer.writerows(inactive_data)\n",
    "\n",
    "print(\"Data has been written to investors.csv\")\n",
    "\n",
    "# 關閉WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a1aea-cf80-427f-b5a3-def06c0aebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# 初始化WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 打开目标网站并等待手动登录\n",
    "driver.get('https://www.rootdata.com/zh/login?fromUrl=%2Fzh%2FInvestors')\n",
    "\n",
    "# 等待手动登录完成\n",
    "time.sleep(30)\n",
    "\n",
    "def extract_data():\n",
    "    data = []\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        print(f\"Currently on page {page_number}\")\n",
    "        \n",
    "        # 找到包含项目信息的表格\n",
    "        table = driver.find_element(By.CSS_SELECTOR, 'table')\n",
    "        \n",
    "        # 获取所有项目的行\n",
    "        rows = table.find_elements(By.CSS_SELECTOR, 'tbody tr')\n",
    "        \n",
    "        for row in rows:\n",
    "            try:\n",
    "                name = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"1\"] a.list_name').text.strip()\n",
    "            except:\n",
    "                name = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                project_url = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"1\"] a.list_name').get_attribute('href')\n",
    "            except:\n",
    "                project_url = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                founded = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"2\"]').text.strip()\n",
    "            except:\n",
    "                founded = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                latest_investment = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"3\"]').text.strip()\n",
    "            except:\n",
    "                latest_investment = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                round_1year = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"4\"]').text.strip()\n",
    "            except:\n",
    "                round_1year = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                portfolio = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"5\"]').text.strip()\n",
    "            except:\n",
    "                portfolio = \"- -\"\n",
    "            \n",
    "            try:\n",
    "                total_raised = row.find_element(By.CSS_SELECTOR, 'td[aria-colindex=\"6\"]').text.strip()\n",
    "            except:\n",
    "                total_raised = \"- -\"\n",
    "            \n",
    "            data.append([name, project_url, founded, latest_investment, round_1year, portfolio, total_raised])\n",
    "        \n",
    "        # 检查是否存在下一页按钮\n",
    "        try:\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # 等待页面加载新数据\n",
    "            page_number += 1\n",
    "        except:\n",
    "            print(\"No more pages or an error occurred.\")\n",
    "            break\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 抓取所有项目数据\n",
    "all_data = extract_data()\n",
    "print(\"Finish crawl all projects\")\n",
    "\n",
    "# 将数据写入CSV文件\n",
    "with open('projects_all.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Name', 'URL', 'Founded', 'Latest Investment', 'Round (1 Year)', 'Portfolio', 'Total Raised'])\n",
    "    writer.writerows(all_data)\n",
    "\n",
    "print(\"Data has been written to projects.csv\")\n",
    "\n",
    "# 关闭WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a506e0d-4a8a-40a4-b00c-71ec2cd0bbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失的記錄已經寫入 investors.csv。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2539/3023544681.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_records['Status'] = 'others'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取 CSV 文件\n",
    "investors_df = pd.read_csv('investors.csv')\n",
    "projects_all_df = pd.read_csv('projects_all.csv')\n",
    "\n",
    "# 將 \"projects_all.csv\" 中的記錄與 \"investors.csv\" 中的記錄進行比較，找出缺失的記錄\n",
    "missing_records = projects_all_df[~projects_all_df['URL'].isin(investors_df['URL'])]\n",
    "\n",
    "# 填充缺失記錄的 \"Status\" 欄位\n",
    "missing_records['Status'] = 'others'\n",
    "\n",
    "# 調整列的順序以匹配 \"investors.csv\" 的結構\n",
    "missing_records = missing_records[['Status', 'Name', 'URL', 'Founded', 'Latest Investment', 'Round (1 Year)', 'Portfolio', 'Total Raised']]\n",
    "\n",
    "# 將缺失記錄追加到 \"investors.csv\"\n",
    "updated_investors_df = pd.concat([investors_df, missing_records])\n",
    "\n",
    "# 將更新後的數據寫回到 \"investors.csv\"\n",
    "updated_investors_df.to_csv('investors.csv', index=False)\n",
    "\n",
    "print(\"缺失的記錄已經寫入 investors.csv。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc116cb6-d8b6-4cff-9d41-9a4b55158062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 projects: Multicoin Capital\n",
      "Processed 200 projects: Solana Ventures\n",
      "Processed 300 projects: Pragma Ventures\n",
      "Processed 400 projects: Jsquare\n",
      "Processed 500 projects: Fasanara Capital\n",
      "Processed 600 projects: Castle Capital\n",
      "Processed 700 projects: Trinito\n",
      "Processed 800 projects: Stateless Ventures\n",
      "Processed 900 projects: DTCC\n",
      "Processed 1000 projects: OtterSec\n",
      "Processed 1100 projects: Celesta Capital\n",
      "Processed 1200 projects: Coho Deeptech\n",
      "Processed 1300 projects: Moore Strategic Ventures\n",
      "Processed 1400 projects: Menyala\n",
      "Processed 1500 projects: Thrive Capital\n",
      "Processed 1600 projects: Avalaunch\n",
      "Processed 1700 projects: EX Capital\n",
      "Processed 1800 projects: Mindworks Capital\n",
      "Processed 1900 projects: 9Yards Capital\n",
      "Processed 2000 projects: Digital Renaissance\n",
      "Processed 2100 projects: Coinsquare\n",
      "Processed 2200 projects: Synapse Ventures\n",
      "Processed 2300 projects: XYZ Venture Capital\n",
      "Processed 2400 projects: Crypto Gaming United\n",
      "Processed 2500 projects: Imec Istart\n",
      "Processed 2600 projects: BAYZ\n",
      "Processed 2700 projects: MCP IPX One Fund（MCP）\n",
      "Processed 2800 projects: Core Innovation Capital\n",
      "Processed 2900 projects: Wings Ventures\n",
      "Processed 3000 projects: Cobak\n",
      "Processed 3100 projects: Canaan\n",
      "Processed 3200 projects: Horizen Labs\n",
      "Processed 3300 projects: AXA Strategic Ventures（AVP）\n",
      "Processed 3400 projects: Viking Capital\n",
      "Processed 3500 projects: Ryan Fang\n",
      "Processed 3600 projects: Justin Waldron\n",
      "Processed 3700 projects: Aleksander Leonard Larsen\n",
      "Processed 3800 projects: Alex Watts\n",
      "Processed 3900 projects: Marin Tvrdić\n",
      "Processed 4000 projects: Tommy Chen\n",
      "Processed 4100 projects: Frederic Montagnon\n",
      "Processed 4200 projects: Ben Middleton\n",
      "Processed 4300 projects: Rohit Goyal\n",
      "Processed 4400 projects: Zahreddine Touag\n",
      "Processed 4500 projects: Joey Santoro\n",
      "Processed 4600 projects: Jack Herrick\n",
      "Processed 4700 projects: Patrick Bucquet\n",
      "Processed 4800 projects: Steve Guo\n",
      "Processed 4900 projects: Christian Baroni\n",
      "Processed 5000 projects: Noah Dummett\n",
      "Processed 5100 projects: Doug Band\n",
      "Processed 5200 projects: Brandon Chez\n",
      "Data has been written to investors_final.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# 初始化WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "def extract_project_data(status, name, url, founded, latest_investment, round_1year, portfolio, total_raised, counter):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # 等待頁面加載\n",
    "\n",
    "    try:\n",
    "        # 爬取項目類別\n",
    "        category = \"- -\"\n",
    "        try:\n",
    "            category_element = driver.find_element(By.XPATH, '//span[text()=\"Category:\"]/following-sibling::div/span')\n",
    "            category = category_element.text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                tags_element = driver.find_element(By.XPATH, '//span[text()=\"Tags:\"]/following-sibling::div/span')\n",
    "                category = tags_element.text.strip()\n",
    "            except:\n",
    "                category = \"- -\"\n",
    "\n",
    "        # 爬取項目地點\n",
    "        location = \"- -\"\n",
    "        try:\n",
    "            location_element = driver.find_element(By.XPATH, '//span[text()=\"Location:\"]/following-sibling::span')\n",
    "            location = location_element.text.strip()\n",
    "        except:\n",
    "            location = \"- -\"\n",
    "\n",
    "        if counter % 100 == 0:\n",
    "            print(f\"Processed {counter} projects: {name}\")\n",
    "\n",
    "        return [status, name, category, location, founded, latest_investment, round_1year, portfolio, total_raised]\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for {name}: {e}\")\n",
    "        return [status, name, \"- -\", \"- -\", founded, latest_investment, round_1year, portfolio, total_raised]\n",
    "\n",
    "# 讀取investors.csv文件\n",
    "with open('investors.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # 跳過標題行\n",
    "    rows = [row for row in reader]\n",
    "\n",
    "# 爬取每個條目的數據\n",
    "all_data = []\n",
    "counter = 0\n",
    "for row in rows:\n",
    "    status, name, url, founded, latest_investment, round_1year, portfolio, total_raised = row\n",
    "    counter += 1\n",
    "    all_data.append(extract_project_data(status, name, url, founded, latest_investment, round_1year, portfolio, total_raised, counter))\n",
    "\n",
    "# 將數據寫入新的CSV文件\n",
    "with open('investors_final.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Status', 'Name', 'Category', 'Location', 'Founded', 'Latest Investment', 'Round (1 Year)', 'Portfolio', 'Total Raised'])\n",
    "    writer.writerows(all_data)\n",
    "\n",
    "print(\"Data has been written to investors_final.csv\")\n",
    "\n",
    "# 關閉WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786af579-87cf-4863-bc03-c26e80494e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
