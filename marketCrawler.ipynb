{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d636b9a-8b09-4c78-a348-ec2ce2caaccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on page 1\n",
      "Currently on page 2\n",
      "Currently on page 3\n",
      "Currently on page 4\n",
      "Currently on page 5\n",
      "Currently on page 6\n",
      "Currently on page 7\n",
      "Currently on page 8\n",
      "Currently on page 9\n",
      "Currently on page 10\n",
      "Currently on page 11\n",
      "Currently on page 12\n",
      "Currently on page 13\n",
      "Currently on page 14\n",
      "Currently on page 15\n",
      "Currently on page 16\n",
      "Currently on page 17\n",
      "Currently on page 18\n",
      "Currently on page 19\n",
      "Currently on page 20\n",
      "Currently on page 21\n",
      "Currently on page 22\n",
      "Currently on page 23\n",
      "Currently on page 24\n",
      "Currently on page 25\n",
      "Currently on page 26\n",
      "Currently on page 27\n",
      "Currently on page 28\n",
      "Currently on page 29\n",
      "Currently on page 30\n",
      "Currently on page 31\n",
      "Currently on page 32\n",
      "Currently on page 33\n",
      "Currently on page 34\n",
      "Currently on page 35\n",
      "Currently on page 36\n",
      "Currently on page 37\n",
      "Currently on page 38\n",
      "Currently on page 39\n",
      "Currently on page 40\n",
      "Currently on page 41\n",
      "Currently on page 42\n",
      "Currently on page 43\n",
      "Currently on page 44\n",
      "Currently on page 45\n",
      "Currently on page 46\n",
      "Currently on page 47\n",
      "Currently on page 48\n",
      "Currently on page 49\n",
      "Currently on page 50\n",
      "Currently on page 51\n",
      "Currently on page 52\n",
      "Currently on page 53\n",
      "Currently on page 54\n",
      "Currently on page 55\n",
      "Currently on page 56\n",
      "Currently on page 57\n",
      "Currently on page 58\n",
      "Currently on page 59\n",
      "Currently on page 60\n",
      "Currently on page 61\n",
      "Currently on page 62\n",
      "Currently on page 63\n",
      "Currently on page 64\n",
      "Currently on page 65\n",
      "Currently on page 66\n",
      "Currently on page 67\n",
      "Currently on page 68\n",
      "Currently on page 69\n",
      "Currently on page 70\n",
      "Currently on page 71\n",
      "Currently on page 72\n",
      "Currently on page 73\n",
      "Currently on page 74\n",
      "Currently on page 75\n",
      "Currently on page 76\n",
      "Currently on page 77\n",
      "Currently on page 78\n",
      "Currently on page 79\n",
      "Currently on page 80\n",
      "Currently on page 81\n",
      "Currently on page 82\n",
      "Currently on page 83\n",
      "Currently on page 84\n",
      "Currently on page 85\n",
      "Currently on page 86\n",
      "Currently on page 87\n",
      "Currently on page 88\n",
      "Currently on page 89\n",
      "Currently on page 90\n",
      "Currently on page 91\n",
      "Currently on page 92\n",
      "No more pages or an error occurred: Message: \n",
      "\n",
      "Data has been exported to market_projects.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 打開目標網站\n",
    "# Crawl all\n",
    "driver.get('https://www.rootdata.com/Market')\n",
    "\n",
    "# 等待網頁加載\n",
    "time.sleep(20)\n",
    "\n",
    "# 初始化數據存儲\n",
    "data = []\n",
    "\n",
    "def get_project_data():\n",
    "    projects = driver.find_elements(By.XPATH, '//tbody/tr')\n",
    "    for project in projects:\n",
    "        try:\n",
    "            rank = project.find_element(By.XPATH, './td[2]').text.strip()\n",
    "            name_element = project.find_element(By.XPATH, './td[3]//div[@class=\"d-flex name\"]//a')\n",
    "            name = name_element.text.strip()\n",
    "            price = project.find_element(By.XPATH, './td[4]').text.strip()\n",
    "            market_cap = project.find_element(By.XPATH, './td[8]').text.strip()\n",
    "            fdv = project.find_element(By.XPATH, './td[9]').text.strip()\n",
    "            link = name_element.get_attribute('href')\n",
    "            data.append({\n",
    "                'Rank': rank,\n",
    "                'Name': name,\n",
    "                'Price': price,\n",
    "                'Market Cap': market_cap,\n",
    "                'FDV': fdv,\n",
    "                'Link': link\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error in parsing project: {e}\")\n",
    "\n",
    "def navigate_pages():\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        print(f\"Currently on page {page_number}\")\n",
    "        get_project_data()\n",
    "        try:\n",
    "            # 檢查是否存在下一頁按鈕\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # 等待頁面加載新數據\n",
    "            page_number += 1\n",
    "        except Exception as e:\n",
    "            print(f\"No more pages or an error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "# 開始抓取數據\n",
    "navigate_pages()\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# 將數據導出到 CSV 文件\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('market_projects.csv', index=False)\n",
    "\n",
    "print(\"Data has been exported to market_projects.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137980d4-1775-457e-ab6c-9c478fd77b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 定義超連結列表\n",
    "urls = [\n",
    "    (\"Binance\", \"https://www.rootdata.com/Market?exp=1__270\"),\n",
    "    (\"Coinbase\", \"https://www.rootdata.com/Market?exp=1__89\"),\n",
    "    (\"OKX\", \"https://www.rootdata.com/Market?exp=1__294\"),\n",
    "    (\"HTX\", \"https://www.rootdata.com/Market?exp=1__102\"),\n",
    "    (\"Bitget\", \"https://www.rootdata.com/Market?exp=1__513\"),\n",
    "    (\"Bybit\", \"https://www.rootdata.com/Market?exp=1__521\"),\n",
    "    (\"Upbit\", \"https://www.rootdata.com/Market?exp=1__351\"),\n",
    "    (\"KuCoin\", \"https://www.rootdata.com/Market?exp=1__311\"),\n",
    "    (\"Kraken\", \"https://www.rootdata.com/Market?exp=1__24\"),\n",
    "    (\"Bitstamp\", \"https://www.rootdata.com/Market?exp=1__70\"),\n",
    "    (\"Bitfinex\", \"https://www.rootdata.com/Market?exp=1__37\"),\n",
    "    (\"MEXC\", \"https://www.rootdata.com/Market?exp=1__544\"),\n",
    "    (\"Crypto.com\", \"https://www.rootdata.com/Market?exp=1__1149\"),\n",
    "    (\"Gate.io\", \"https://www.rootdata.com/Market?exp=1__302\"),\n",
    "    (\"Gemini\", \"https://www.rootdata.com/Market?exp=1__151\"),\n",
    "    (\"bitFlyer\", \"https://www.rootdata.com/Market?exp=1__139\"),\n",
    "    (\"Bithumb\", \"https://www.rootdata.com/Market?exp=1__200\"),\n",
    "]\n",
    "\n",
    "# 首次訪問市場頁面，等待20秒\n",
    "driver.get(\"https://www.rootdata.com/Market\")\n",
    "time.sleep(20)\n",
    "\n",
    "# 打開文件準備寫入\n",
    "with open('market_exchange.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Exchange\", \"Rank\", \"Name\"])\n",
    "\n",
    "    for exchange, url in urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(10)  # 等待網頁加載\n",
    "        \n",
    "        while True:\n",
    "            projects = driver.find_elements(By.XPATH, \"//table/tbody/tr\")\n",
    "            for project in projects:\n",
    "                try:\n",
    "                    rank = project.find_element(By.XPATH, \"./td[2]\").text.strip()\n",
    "                    full_name = project.find_element(By.XPATH, \"./td[3]//a[contains(@class, 'list_name')]\").text.strip()\n",
    "                    writer.writerow([exchange, rank, full_name])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in parsing project: {e}\")\n",
    "\n",
    "            # 檢查是否存在下一頁按鈕並點擊\n",
    "            try:\n",
    "                wait = WebDriverWait(driver, 10)\n",
    "                next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "                next_button.click()\n",
    "                time.sleep(5)  # 等待頁面加載新數據\n",
    "            except:\n",
    "                print(\"No more pages or an error occurred.\")\n",
    "                break\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54d98742-1610-475b-a962-25aa6a692c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exchange, url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[1;32m     73\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 等待網頁加載\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         projects \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//table/tbody/tr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 定義超連結列表\n",
    "urls = [\n",
    "    (\"BitMEX\", \"https://www.rootdata.com/Market?exp=1__157\"),\n",
    "    (\"Coincheck\", \"https://www.rootdata.com/Market?exp=1__106\"),\n",
    "    (\"Uniswap\", \"https://www.rootdata.com/Market?exp=1__1069\"),\n",
    "    (\"PancakeSwap\", \"https://www.rootdata.com/Market?exp=1__1165\"),\n",
    "    (\"Osmosis\", \"https://www.rootdata.com/Market?exp=1__1447\"),\n",
    "    (\"QuickSwap\", \"https://www.rootdata.com/Market?exp=1__1293\"),\n",
    "    (\"Camelot\", \"https://www.rootdata.com/Market?exp=1__5101\"),\n",
    "    (\"Raydium\", \"https://www.rootdata.com/Market?exp=1__1342\"),\n",
    "    (\"Astroport\", \"https://www.rootdata.com/Market?exp=1__1614\"),\n",
    "    (\"TraderJoe\", \"https://www.rootdata.com/Market?exp=1__1456\"),\n",
    "    (\"Orca\", \"https://www.rootdata.com/Market?exp=1__1426\"),\n",
    "    (\"Jupiter\", \"https://www.rootdata.com/Market?exp=1__1612\"),\n",
    "    (\"SushiSwap\", \"https://www.rootdata.com/Market?exp=1__1141\"),\n",
    "    (\"Cetus\", \"https://www.rootdata.com/Market?exp=1__6993\"),\n",
    "    (\"OpenOcean\", \"https://www.rootdata.com/Market?exp=1__1261\"),\n",
    "    (\"SyncSwap\", \"https://www.rootdata.com/Market?exp=1__6813\"),\n",
    "    (\"XT.COM\", \"https://www.rootdata.com/Market?exp=1__525\"),\n",
    "]\n",
    "\n",
    "# 首次訪問市場頁面，等待20秒\n",
    "driver.get(\"https://www.rootdata.com/Market\")\n",
    "time.sleep(20)\n",
    "\n",
    "# 打開文件準備寫入\n",
    "with open('market_exchange.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Exchange\", \"Rank\", \"Name\"])\n",
    "\n",
    "    for exchange, url in urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(10)  # 等待網頁加載\n",
    "        \n",
    "        while True:\n",
    "            projects = driver.find_elements(By.XPATH, \"//table/tbody/tr\")\n",
    "            for project in projects:\n",
    "                try:\n",
    "                    rank = project.find_element(By.XPATH, \"./td[2]\").text.strip()\n",
    "                    full_name = project.find_element(By.XPATH, \"./td[3]//a[contains(@class, 'list_name')]\").text.strip()\n",
    "                    writer.writerow([exchange, rank, full_name])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in parsing project: {e}\")\n",
    "\n",
    "            # 檢查是否存在下一頁按鈕並點擊\n",
    "            try:\n",
    "                wait = WebDriverWait(driver, 10)\n",
    "                next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "                next_button.click()\n",
    "                time.sleep(5)  # 等待頁面加載新數據\n",
    "            except:\n",
    "                print(\"No more pages or an error occurred.\")\n",
    "                break\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "714b91ad-80d2-4deb-9581-e62233576a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n",
      "No more pages or an error occurred.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 定義超連結列表\n",
    "urls = [\n",
    "    (\"ProBit\", \"https://www.rootdata.com/Market?exp=1__1405\"),\n",
    "    (\"Deepcoin\", \"https://www.rootdata.com/Market?exp=1__1182\"),\n",
    "    (\"LATOKEN\", \"https://www.rootdata.com/Market?exp=1__380\"),\n",
    "    (\"LBank\", \"https://www.rootdata.com/Market?exp=1__333\"),\n",
    "    (\"BingX\", \"https://www.rootdata.com/Market?exp=1__1064\"),\n",
    "    (\"BitMart\", \"https://www.rootdata.com/Market?exp=1__406\"),\n",
    "    (\"WhiteBIT\", \"https://www.rootdata.com/Market?exp=1__501\"),\n",
    "    (\"Phemex\", \"https://www.rootdata.com/Market?exp=1__955\"),\n",
    "    (\"AscendEX\", \"https://www.rootdata.com/Market?exp=1__453\"),\n",
    "    (\"Toolbit\", \"https://www.rootdata.com/Market?exp=1__6137\"),\n",
    "    (\"Coinone\", \"https://www.rootdata.com/Market?exp=1__174\"),\n",
    "    (\"Bitrue\", \"https://www.rootdata.com/Market?exp=1__433\"),\n",
    "    (\"Poloniex\", \"https://www.rootdata.com/Market?exp=1__16\"),\n",
    "    (\"Bitkub\", \"https://www.rootdata.com/Market?exp=1__436\"),\n",
    "    (\"Bitbank\", \"https://www.rootdata.com/Market?exp=1__257\"),\n",
    "    (\"Currency.com\", \"https://www.rootdata.com/Market?exp=1__699\"),\n",
    "    (\"Coinstore\", \"https://www.rootdata.com/Market?exp=1__1411\"),\n",
    "    (\"Tokocrypto\", \"https://www.rootdata.com/Market?exp=1__710\"),\n",
    "    (\"Zaif\", \"https://www.rootdata.com/Market?exp=1__73\"),\n",
    "    (\"Bitvavo\", \"https://www.rootdata.com/Market?exp=1__520\"),\n",
    "    (\"Luno\", \"https://www.rootdata.com/Market?exp=1__171\"),\n",
    "    (\"Bitso\", \"https://www.rootdata.com/Market?exp=1__125\"),\n",
    "    (\"HashKeyExchange\", \"https://www.rootdata.com/Market?exp=1__795\"),\n",
    "    (\"Coinlist\", \"https://www.rootdata.com/Market?exp=1__1011\"),\n",
    "    (\"Bullish\", \"https://www.rootdata.com/Market?exp=1__1601\"),\n",
    "    (\"FameEX\", \"https://www.rootdata.com/Market?exp=1__1247\"),\n",
    "    (\"BIGONE\", \"https://www.rootdata.com/Market?exp=1__330\"),\n",
    "    (\"Bilaxy\", \"https://www.rootdata.com/Market?exp=1__415\"),\n",
    "    (\"CoinEx\", \"https://www.rootdata.com/Market?exp=1__350\"),\n",
    "    (\"HitBTC\", \"https://www.rootdata.com/Market?exp=1__42\"),\n",
    "    (\"BTSE\", \"https://www.rootdata.com/Market?exp=1__658\"),\n",
    "]\n",
    "\n",
    "# 首次訪問市場頁面，等待20秒\n",
    "driver.get(\"https://www.rootdata.com/Market\")\n",
    "time.sleep(20)\n",
    "\n",
    "# 打開文件準備寫入\n",
    "with open('market_exchange.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Exchange\", \"Rank\", \"Name\"])\n",
    "\n",
    "    for exchange, url in urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(10)  # 等待網頁加載\n",
    "        \n",
    "        while True:\n",
    "            projects = driver.find_elements(By.XPATH, \"//table/tbody/tr\")\n",
    "            for project in projects:\n",
    "                try:\n",
    "                    rank = project.find_element(By.XPATH, \"./td[2]\").text.strip()\n",
    "                    full_name = project.find_element(By.XPATH, \"./td[3]//a[contains(@class, 'list_name')]\").text.strip()\n",
    "                    writer.writerow([exchange, rank, full_name])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in parsing project: {e}\")\n",
    "\n",
    "            # 檢查是否存在下一頁按鈕並點擊\n",
    "            try:\n",
    "                wait = WebDriverWait(driver, 10)\n",
    "                next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "                next_button.click()\n",
    "                time.sleep(5)  # 等待頁面加載新數據\n",
    "            except:\n",
    "                print(\"No more pages or an error occurred.\")\n",
    "                break\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "009e1257-78b3-438c-8f10-9dad21d601c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecosystem details saved to market_projects_eco.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# 初始化 WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 讀取 CSV 文件\n",
    "input_csv_file = 'market_projects.csv'\n",
    "output_csv_file = 'market_projects_eco.csv'\n",
    "\n",
    "# 打開輸出 CSV 文件\n",
    "with open(output_csv_file, mode='w', newline='', encoding='utf-8') as output_file:\n",
    "    writer = csv.writer(output_file)\n",
    "    writer.writerow(['Rank', 'Name', 'Price', 'Market Cap', 'FDV', 'Ecosystem'])\n",
    "    \n",
    "    # 讀取輸入 CSV 文件\n",
    "    with open(input_csv_file, mode='r', newline='', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        \n",
    "        for row in reader:\n",
    "            rank = row['Rank']\n",
    "            name = row['Name']\n",
    "            price = row['Price']\n",
    "            market_cap = row['Market Cap']\n",
    "            fdv = row['FDV']\n",
    "            link = row['Link']\n",
    "            \n",
    "            # 打開每個項目的鏈接\n",
    "            driver.get(link)\n",
    "            time.sleep(3)  # 等待頁面加載\n",
    "            \n",
    "            # 檢查是否存在生態系統信息\n",
    "            try:\n",
    "                ecosystem_label = driver.find_element(By.XPATH, '//span[contains(text(), \"Ecosystem\")]')\n",
    "                parent_element = ecosystem_label.find_element(By.XPATH, '..')\n",
    "                ecosystem_elements = parent_element.find_elements(By.XPATH, './/a/span')\n",
    "                ecosystems = [elem.text for elem in ecosystem_elements]\n",
    "                ecosystem_str = ', '.join(ecosystems) if ecosystems else 'N/A'\n",
    "            except:\n",
    "                ecosystem_str = 'N/A'\n",
    "            \n",
    "            # 寫入輸出 CSV 文件\n",
    "            writer.writerow([rank, name, price, market_cap, fdv, ecosystem_str])\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n",
    "\n",
    "print(f'Ecosystem details saved to {output_csv_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6257902-a7d1-4970-8080-8fea9ca32e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件已成功合併並保存為 market_project_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取 CSV 文件，指定編碼為 'ISO-8859-1'\n",
    "market_projects_eco = pd.read_csv('market_projects_eco.csv', encoding='ISO-8859-1')\n",
    "market_exchange = pd.read_csv('market_exchange.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# 將相同 Rank 和 Name 的 Exchange 合併為一個欄位\n",
    "market_exchange_grouped = market_exchange.groupby(['Rank', 'Name'])['Exchange'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "\n",
    "# 合併兩個 DataFrame\n",
    "merged_data = pd.merge(market_projects_eco, market_exchange_grouped, on=['Rank', 'Name'], how='left')\n",
    "\n",
    "# 將合併後的數據保存到新的 CSV 文件\n",
    "merged_data.to_csv('market_project_summary.csv', index=False)\n",
    "\n",
    "print(\"CSV 文件已成功合併並保存為 market_project_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2aec4acf-7e9e-4577-a438-ba3bee3e9208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on page 1\n",
      "Currently on page 2\n",
      "Currently on page 3\n",
      "Currently on page 4\n",
      "No more pages or an error occurred: Message: \n",
      "\n",
      "Data has been exported to market_projects.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 打開目標網站\n",
    "# Crawl AI(need manually login)\n",
    "driver.get('https://www.rootdata.com/Market?tagId=198')\n",
    "\n",
    "# 等待網頁加載\n",
    "time.sleep(20)\n",
    "\n",
    "# 初始化數據存儲\n",
    "data = []\n",
    "\n",
    "def get_project_data():\n",
    "    projects = driver.find_elements(By.XPATH, '//tbody/tr')\n",
    "    for project in projects:\n",
    "        try:\n",
    "            rank = project.find_element(By.XPATH, './td[2]').text.strip()\n",
    "            name_element = project.find_element(By.XPATH, './td[3]//div[@class=\"d-flex name\"]//a')\n",
    "            name = name_element.text.strip()\n",
    "            price = project.find_element(By.XPATH, './td[4]').text.strip()\n",
    "            market_cap = project.find_element(By.XPATH, './td[8]').text.strip()\n",
    "            fdv = project.find_element(By.XPATH, './td[9]').text.strip()\n",
    "            link = name_element.get_attribute('href')\n",
    "            data.append({\n",
    "                'Rank': rank,\n",
    "                'Name': name,\n",
    "                'Price': price,\n",
    "                'Market Cap': market_cap,\n",
    "                'FDV': fdv,\n",
    "                'Link': link\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error in parsing project: {e}\")\n",
    "\n",
    "def navigate_pages():\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        print(f\"Currently on page {page_number}\")\n",
    "        get_project_data()\n",
    "        try:\n",
    "            # 檢查是否存在下一頁按鈕\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # 等待頁面加載新數據\n",
    "            page_number += 1\n",
    "        except Exception as e:\n",
    "            print(f\"No more pages or an error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "# 開始抓取數據\n",
    "navigate_pages()\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# 將數據導出到 CSV 文件\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('market_projects_AI.csv', index=False)\n",
    "\n",
    "print(\"Data has been exported to market_projects_AI.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d2e3a80-ea56-4522-b227-372151c12c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on page 1\n",
      "Currently on page 2\n",
      "Currently on page 3\n",
      "Currently on page 4\n",
      "Currently on page 5\n",
      "Currently on page 6\n",
      "Currently on page 7\n",
      "Currently on page 8\n",
      "Currently on page 9\n",
      "Currently on page 10\n",
      "Currently on page 11\n",
      "No more pages or an error occurred: Message: \n",
      "\n",
      "Data has been exported to market_projects_Game.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 打開目標網站\n",
    "# Crawl Game(need manually login)\n",
    "driver.get('https://www.rootdata.com/Market?tagId=111')\n",
    "\n",
    "# 等待網頁加載\n",
    "time.sleep(20)\n",
    "\n",
    "# 初始化數據存儲\n",
    "data = []\n",
    "\n",
    "def get_project_data():\n",
    "    projects = driver.find_elements(By.XPATH, '//tbody/tr')\n",
    "    for project in projects:\n",
    "        try:\n",
    "            rank = project.find_element(By.XPATH, './td[2]').text.strip()\n",
    "            name_element = project.find_element(By.XPATH, './td[3]//div[@class=\"d-flex name\"]//a')\n",
    "            name = name_element.text.strip()\n",
    "            price = project.find_element(By.XPATH, './td[4]').text.strip()\n",
    "            market_cap = project.find_element(By.XPATH, './td[8]').text.strip()\n",
    "            fdv = project.find_element(By.XPATH, './td[9]').text.strip()\n",
    "            link = name_element.get_attribute('href')\n",
    "            data.append({\n",
    "                'Rank': rank,\n",
    "                'Name': name,\n",
    "                'Price': price,\n",
    "                'Market Cap': market_cap,\n",
    "                'FDV': fdv,\n",
    "                'Link': link\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error in parsing project: {e}\")\n",
    "\n",
    "def navigate_pages():\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        print(f\"Currently on page {page_number}\")\n",
    "        get_project_data()\n",
    "        try:\n",
    "            # 檢查是否存在下一頁按鈕\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # 等待頁面加載新數據\n",
    "            page_number += 1\n",
    "        except Exception as e:\n",
    "            print(f\"No more pages or an error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "# 開始抓取數據\n",
    "navigate_pages()\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# 將數據導出到 CSV 文件\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('market_projects_Game.csv', index=False)\n",
    "\n",
    "print(\"Data has been exported to market_projects_Game.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71fcea35-10cd-460b-9618-c7b525457bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on page 1\n",
      "Currently on page 2\n",
      "Currently on page 3\n",
      "No more pages or an error occurred: Message: \n",
      "\n",
      "Data has been exported to market_projects_Social.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 打開目標網站\n",
    "# Crawl Game(need manually login)\n",
    "driver.get('https://www.rootdata.com/Market?tagId=140')\n",
    "\n",
    "# 等待網頁加載\n",
    "time.sleep(20)\n",
    "\n",
    "# 初始化數據存儲\n",
    "data = []\n",
    "\n",
    "def get_project_data():\n",
    "    projects = driver.find_elements(By.XPATH, '//tbody/tr')\n",
    "    for project in projects:\n",
    "        try:\n",
    "            rank = project.find_element(By.XPATH, './td[2]').text.strip()\n",
    "            name_element = project.find_element(By.XPATH, './td[3]//div[@class=\"d-flex name\"]//a')\n",
    "            name = name_element.text.strip()\n",
    "            price = project.find_element(By.XPATH, './td[4]').text.strip()\n",
    "            market_cap = project.find_element(By.XPATH, './td[8]').text.strip()\n",
    "            fdv = project.find_element(By.XPATH, './td[9]').text.strip()\n",
    "            link = name_element.get_attribute('href')\n",
    "            data.append({\n",
    "                'Rank': rank,\n",
    "                'Name': name,\n",
    "                'Price': price,\n",
    "                'Market Cap': market_cap,\n",
    "                'FDV': fdv,\n",
    "                'Link': link\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error in parsing project: {e}\")\n",
    "\n",
    "def navigate_pages():\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        print(f\"Currently on page {page_number}\")\n",
    "        get_project_data()\n",
    "        try:\n",
    "            # 檢查是否存在下一頁按鈕\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # 等待頁面加載新數據\n",
    "            page_number += 1\n",
    "        except Exception as e:\n",
    "            print(f\"No more pages or an error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "# 開始抓取數據\n",
    "navigate_pages()\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# 將數據導出到 CSV 文件\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('market_projects_Social.csv', index=False)\n",
    "\n",
    "print(\"Data has been exported to market_projects_Social.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a600606-4f13-4a73-9f8b-29905274a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on page 1\n",
      "Currently on page 2\n",
      "No more pages or an error occurred: Message: \n",
      "\n",
      "Data has been exported to market_projects_Wallet.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化 WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 打開目標網站\n",
    "# Crawl Game(need manually login)\n",
    "driver.get('https://www.rootdata.com/Market?tagId=54')\n",
    "\n",
    "# 等待網頁加載\n",
    "time.sleep(20)\n",
    "\n",
    "# 初始化數據存儲\n",
    "data = []\n",
    "\n",
    "def get_project_data():\n",
    "    projects = driver.find_elements(By.XPATH, '//tbody/tr')\n",
    "    for project in projects:\n",
    "        try:\n",
    "            rank = project.find_element(By.XPATH, './td[2]').text.strip()\n",
    "            name_element = project.find_element(By.XPATH, './td[3]//div[@class=\"d-flex name\"]//a')\n",
    "            name = name_element.text.strip()\n",
    "            price = project.find_element(By.XPATH, './td[4]').text.strip()\n",
    "            market_cap = project.find_element(By.XPATH, './td[8]').text.strip()\n",
    "            fdv = project.find_element(By.XPATH, './td[9]').text.strip()\n",
    "            link = name_element.get_attribute('href')\n",
    "            data.append({\n",
    "                'Rank': rank,\n",
    "                'Name': name,\n",
    "                'Price': price,\n",
    "                'Market Cap': market_cap,\n",
    "                'FDV': fdv,\n",
    "                'Link': link\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error in parsing project: {e}\")\n",
    "\n",
    "def navigate_pages():\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        print(f\"Currently on page {page_number}\")\n",
    "        get_project_data()\n",
    "        try:\n",
    "            # 檢查是否存在下一頁按鈕\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn-next')))\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # 等待頁面加載新數據\n",
    "            page_number += 1\n",
    "        except Exception as e:\n",
    "            print(f\"No more pages or an error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "# 開始抓取數據\n",
    "navigate_pages()\n",
    "\n",
    "# 關閉 WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# 將數據導出到 CSV 文件\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('market_projects_Wallet.csv', index=False)\n",
    "\n",
    "print(\"Data has been exported to market_projects_Wallet.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ae39927-4ecc-4aaa-b999-d56cdd331d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件已成功合併並保存為 market_projects_filter.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取 CSV 文件\n",
    "market_projects_ai = pd.read_csv('market_projects_AI.csv', encoding='ISO-8859-1')\n",
    "market_projects_game = pd.read_csv('market_projects_Game.csv', encoding='ISO-8859-1')\n",
    "market_projects_social = pd.read_csv('market_projects_Social.csv', encoding='ISO-8859-1')\n",
    "market_projects_wallet = pd.read_csv('market_projects_Wallet.csv', encoding='ISO-8859-1')\n",
    "market_project_final = pd.read_csv('market_project_final.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# 添加過濾欄位\n",
    "market_projects_ai['Filter'] = 'AI'\n",
    "market_projects_game['Filter'] = 'Game'\n",
    "market_projects_social['Filter'] = 'Social'\n",
    "market_projects_wallet['Filter'] = 'Wallet'\n",
    "\n",
    "# 合併所有項目數據\n",
    "all_projects = pd.concat([market_projects_ai, market_projects_game, market_projects_social, market_projects_wallet])\n",
    "\n",
    "# 將 market_project_final 中的 \"Rank\", \"Name\", \"Ecosystem\", \"Exchange\" 加入到所有項目數據中\n",
    "merged_data = pd.merge(all_projects, market_project_final[['Rank', 'Name', 'Ecosystem', 'Exchange']], on=['Rank', 'Name'], how='left')\n",
    "\n",
    "# 針對相同的 Rank 和 Name 合併 Exchange 欄位\n",
    "merged_data['Exchange'] = merged_data.groupby(['Rank', 'Name'])['Exchange'].transform(lambda x: ', '.join(x.dropna().unique()))\n",
    "\n",
    "# 刪除重複的行並保留第一個\n",
    "merged_data = merged_data.drop_duplicates(subset=['Rank', 'Name', 'Filter', 'Price', 'Market Cap', 'FDV', 'Ecosystem', 'Exchange'])\n",
    "\n",
    "# 將合併後的數據保存到新的 CSV 文件\n",
    "merged_data.to_csv('market_projects_filter_final.csv', index=False)\n",
    "\n",
    "print(\"CSV 文件已成功合併並保存為 market_projects_filter.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5a73c-5e20-4cfc-bf8e-bcccb981a04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
